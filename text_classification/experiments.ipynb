{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import itertools\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import fasttext.util\n",
    "from joblib import dump, load\n",
    "import pymorphy2\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = ['привет как дела', 'привет', 'что делаешь', 'что ты умеешь',\n",
    "          'ты тупой', 'какая погода', 'в радуге 7 цветов', \n",
    "          'какая-то рандомная фраза', 'пока', 'всего хорошего']\n",
    "other_df = pd.DataFrame({'Пример текста': other, 'Класс': ['OTHER']*len(other)})\n",
    "df = df.append(other_df)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = pd.factorize(df['Класс'])[0]\n",
    "df.rename({'Пример текста': 'text'}, axis=1, inplace=True)\n",
    "\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "other = ['здравствуйте', 'чем занимаетесь', 'какие у тебя функции',\n",
    "         'ты меня не понимаешь', 'до свидания']\n",
    "other_df = pd.DataFrame({'Пример текста': other, 'Класс': ['OTHER']*len(other)})\n",
    "test_df = test_df.append(other_df)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_df['label'] = pd.factorize(test_df['Класс'])[0]\n",
    "\n",
    "X_test_text = test_df['Пример текста']\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Класс</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу в отпуск</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>мне бы в отдохнуть</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>как мне взять отпуск</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>хочу отгул на следующей неделе</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>хочу улететь в турцию</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text             Класс  label\n",
       "0                   хочу в отпуск  VACATION-REQUEST      0\n",
       "1              мне бы в отдохнуть  VACATION-REQUEST      0\n",
       "2            как мне взять отпуск  VACATION-REQUEST      0\n",
       "3  хочу отгул на следующей неделе  VACATION-REQUEST      0\n",
       "4           хочу улететь в турцию  VACATION-REQUEST      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0: 'VACATION-REQUEST', 1: 'SALARY-REQUEST',\n",
    "               2: 'SICK-LEAVE-REPORT', 3: 'OTHER'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(data: List[List]):\n",
    "    col_width = max(len(word) for row in data for word in row) + 2  # padding\n",
    "    for row in data:\n",
    "        print(\"\".join(word.ljust(col_width) for word in row))\n",
    "\n",
    "def print_errors(y_test, y_pred):\n",
    "    wrong_idx = [idx for idx, (x, y) in enumerate(zip(y_pred, y_test)) if x!= y]\n",
    "\n",
    "    data = [['Text', 'Classificator']]\n",
    "    for idx in wrong_idx:\n",
    "        data.append([X_test_text[idx], labels_dict[y_pred[idx]]])\n",
    "    pretty_print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVec + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(df.text)\n",
    "y_train = df.label.values\n",
    "\n",
    "X_test = vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       0.60      0.75      0.67         4\n",
      "           3       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.85      0.82      0.83        17\n",
      "weighted avg       0.85      0.82      0.83        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text                     Classificator            \n",
      "Как мне получить оптуск  SICK-LEAVE-REPORT        \n",
      "Бльничный нужен          OTHER                    \n",
      "ты меня не понимаешь     SICK-LEAVE-REPORT        \n"
     ]
    }
   ],
   "source": [
    "print_errors(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVec + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       0.60      0.75      0.67         4\n",
      "           3       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.85      0.82      0.83        17\n",
      "weighted avg       0.85      0.82      0.83        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one-vs-rest\n",
    "clf = svm.LinearSVC().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       1.00      0.75      0.86         4\n",
      "           2       0.40      0.50      0.44         4\n",
      "           3       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.74      0.70      0.71        17\n",
      "weighted avg       0.74      0.71      0.72        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one-vs-one\n",
    "clf = svm.SVC(decision_function_shape='ovo').fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVec + MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num of iterations: (50, 'lbfgs', 'logistic')\n"
     ]
    }
   ],
   "source": [
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "iterations = [50, 100, 150, 200]\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "activations = ['identity', 'logistic', 'tanh', 'relu']\n",
    "params_tuples = list(itertools.product(iterations, solvers, activations))\n",
    "\n",
    "scores = []\n",
    "for it, solver, activation in params_tuples:\n",
    "    clf = MLPClassifier(random_state=42, max_iter=it, \n",
    "                        solver=solver, activation=activation).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(f'Best num of iterations: {params_tuples[scores.index(max(scores))]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       0.75      0.75      0.75         4\n",
      "           3       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.90      0.88      0.88        17\n",
      "weighted avg       0.89      0.88      0.88        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=42, max_iter=50, \n",
    "                    solver='lbfgs', activation='logistic').fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('data/cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [ft.get_sentence_vector(sent) for sent in df.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict([ft.get_sentence_vector(sent) for sent in test_df['Пример текста']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.57      1.00      0.73         4\n",
      "           2       1.00      0.50      0.67         4\n",
      "           3       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.83      0.76      0.76        17\n",
      "weighted avg       0.84      0.76      0.77        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText + MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num of iterations: (50, 'lbfgs', 'identity')\n"
     ]
    }
   ],
   "source": [
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "iterations = [50, 100, 150, 200]\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "activations = ['identity', 'logistic', 'tanh', 'relu']\n",
    "params_tuples = list(itertools.product(iterations, solvers, activations))\n",
    "\n",
    "scores = []\n",
    "for it, solver, activation in params_tuples:\n",
    "    clf = MLPClassifier(random_state=42, max_iter=it, \n",
    "                        solver=solver, activation=activation).fit(X_train, y_train)\n",
    "    y_pred = clf.predict([ft.get_sentence_vector(sent) for sent in test_df['Пример текста']])\n",
    "    scores.append(f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(f'Best num of iterations: {params_tuples[scores.index(max(scores))]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.80      1.00      0.89         4\n",
      "           2       0.80      1.00      0.89         4\n",
      "           3       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.90      0.89      0.88        17\n",
      "weighted avg       0.91      0.88      0.88        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=42, max_iter=50, \n",
    "                    solver='lbfgs', activation='identity').fit(X_train, y_train)\n",
    "y_pred = clf.predict([ft.get_sentence_vector(sent) for sent in test_df['Пример текста']])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.57      1.00      0.73         4\n",
      "           2       1.00      0.50      0.67         4\n",
      "           3       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.83      0.76      0.76        17\n",
      "weighted avg       0.84      0.76      0.77        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one-vs-rest\n",
    "clf = svm.LinearSVC().fit(X_train, y_train)\n",
    "y_pred = clf.predict([ft.get_sentence_vector(sent) for sent in test_df['Пример текста']])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       0.60      0.75      0.67         4\n",
      "           3       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.84      0.82      0.83        17\n",
      "weighted avg       0.85      0.82      0.83        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one-vs-one\n",
    "clf = svm.SVC(decision_function_shape='ovo').fit(X_train, y_train)\n",
    "y_pred = clf.predict([ft.get_sentence_vector(sent) for sent in test_df['Пример текста']])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_form(word, morph):\n",
    "    return morph.parse(word)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(word, morph):\n",
    "    return morph.parse(word)[0].tag.POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_grammer_names(morh_grammer_name):\n",
    "#     dict_morph_to_rusvectores = {'ADJF': 'ADJ', 'ADJS': 'ADJ'}\n",
    "    dict_morph_to_rusvectores = {'NOUN':'NOUN'}\n",
    "    return dict_morph_to_rusvectores.get(morh_grammer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    url = f'https://rusvectores.org/tayga_upos_skipgram_300_2_2019/{word}/api/csv/'\n",
    "    r = requests.get(url)\n",
    "    word_pos_df = pd.read_csv(StringIO(r.text), header=None, skiprows=2, sep='\\t')\n",
    "    return word_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_synonyms(df, word, pos='ADJ'):\n",
    "    df['pos'] = df[0].apply(lambda x: x.split('_')[1])\n",
    "    df['word'] = df[0].apply(lambda x: x.split('_')[0])\n",
    "    df = df[df.pos == pos]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    if df['word'][0] == word:\n",
    "        return df['word'][1]\n",
    "    return df['word'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(sent):\n",
    "    sent = sent.split(' ')\n",
    "    for idx, word in enumerate(sent):\n",
    "        word = get_normal_form(word, morph)\n",
    "        morph_pos = get_pos(word, morph)\n",
    "        rus_vectores_pos = transform_grammer_names(morph_pos)\n",
    "        if rus_vectores_pos:\n",
    "            syn_df = get_synonyms(word + '_' + rus_vectores_pos)\n",
    "            syn = filter_synonyms(syn_df, word, pos='NOUN')\n",
    "            sent[idx] = syn\n",
    "        else:\n",
    "            continue\n",
    "    return ' '.join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['aug'] = df.text.apply(replace_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Класс</th>\n",
       "      <th>label</th>\n",
       "      <th>aug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хочу в отпуск</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "      <td>хочу в отгул</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>мне бы в отдохнуть</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "      <td>мне бы в отдохнуть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>как мне взять отпуск</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "      <td>как мне взять отгул</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>хочу отгул на следующей неделе</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "      <td>хочу отпуск на следующей месяц</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>хочу улететь в турцию</td>\n",
       "      <td>VACATION-REQUEST</td>\n",
       "      <td>0</td>\n",
       "      <td>хочу улететь в россия</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text             Класс  label  \\\n",
       "0                   хочу в отпуск  VACATION-REQUEST      0   \n",
       "1              мне бы в отдохнуть  VACATION-REQUEST      0   \n",
       "2            как мне взять отпуск  VACATION-REQUEST      0   \n",
       "3  хочу отгул на следующей неделе  VACATION-REQUEST      0   \n",
       "4           хочу улететь в турцию  VACATION-REQUEST      0   \n",
       "\n",
       "                              aug  \n",
       "0                    хочу в отгул  \n",
       "1              мне бы в отдохнуть  \n",
       "2             как мне взять отгул  \n",
       "3  хочу отпуск на следующей месяц  \n",
       "4           хочу улететь в россия  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part = df[['text', 'label']].copy()\n",
    "second_part = df[['aug', 'label']].copy()\n",
    "second_part.rename({'aug': 'text'}, axis=1, inplace=True)\n",
    "aug_df = first_part.append(second_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.75      0.75      0.75         4\n",
      "           2       0.75      0.75      0.75         4\n",
      "           3       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.78      0.76      0.76        17\n",
      "weighted avg       0.79      0.76      0.77        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = [ft.get_sentence_vector(sent) for sent in aug_df.text]\n",
    "y_train = aug_df.label.values\n",
    "clf = MLPClassifier(random_state=42, max_iter=50, \n",
    "                    solver='lbfgs', activation='identity').fit(X_train, y_train)\n",
    "y_pred = clf.predict([ft.get_sentence_vector(sent) for sent in test_df['Пример текста']])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.80      1.00      0.89         4\n",
      "           2       0.80      1.00      0.89         4\n",
      "           3       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.90      0.89      0.88        17\n",
      "weighted avg       0.91      0.88      0.88        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = [ft.get_sentence_vector(sent) for sent in df.text]\n",
    "y_train = df.label.values\n",
    "clf = MLPClassifier(random_state=42, max_iter=50, \n",
    "                    solver='lbfgs', activation='identity').fit(X_train, y_train)\n",
    "y_pred = clf.predict([ft.get_sentence_vector(sent) for sent in test_df['Пример текста']])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext_mlpclassifier.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf, 'fasttext_mlpclassifier.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "В рамках экспериментов попробовала BOW и FastText представления слов. Так как тестовый датасет очень маленький сложно объективно оценить на сколько хорошо работает модель. Лучше всех показали себя FastText + MLPClassifier, macro avg f1-score: 0.88.\n",
    "Также, попробовала аугментировать тренировочный датасет, путем замены слов на синонимы. Для нахождения синонимов использовала rusvectores, для нахождения части речи использовала pymorphy2. Сначала пробовала заменять прилагательные и увидела, что замены получились не очень, тогда заменила существительные, что в принципе было приемлимло. Дальше попробовала применить лучшую полученную модель MLPClassifier с FastText эмбеддингами, результаты не улучшились. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Будущие эксперименты\n",
    "\n",
    "#### Идеи с классификатором \n",
    "Так как датасет очень маленький, думаю, что тут хорошо будут работать и rule-based алгоритмы. \n",
    "\n",
    "#### Идеи с представлениями слов\n",
    "Можно попробовать tf-idf. Если расширить датасет, то можно попробовать ELMo.\n",
    "\n",
    "#### Идеи с аугментацией данных\n",
    "Какую-то часть можно нагенерить руками. Также, можно поискать фразы в интернете, например, на сайтах изучения английского языка часто бывает наборы фраз, разделенные на интенты [пример](https://skyeng.ru/articles/100-poleznyh-razgovornyh-fraz-na-anglijskom). Когда данных будет больше, можно попробовать генеративные модели для генерации текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
